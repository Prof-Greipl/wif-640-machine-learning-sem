{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IML_301 A Single Neuron.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WP54qWJD8gXI","colab_type":"text"},"source":["# Mathematics\n","\n","## Definition of a Neuron\n","\n","A Neuron $Q$ denotes a triple $(D, w^T, b, \\sigma)$ with\n","\n","- $d \\in \\mathbb{N}$ defines the dimension of a vector to be processed by the neuron. Less formally we talk about the number if incoming values, or *incoming activations*\n","- $\\sigma :\\mathbb{R} \\rightarrow \\mathbb{R}$, denoting a function called the **activation function** of the current layer\n","- $w \\in \\mathbb{R}^{d}$ denoting the **weight column vector** (or short: weight) of the neuron\n","- $b \\in \\mathbb{R}$ is called the  **bias** of the neuron\n","\n","## Activation of a Neuron\n","The next equation defines the processing behavior of a neuron Q:\n","\n","$$\n","Q : \\mathbb{R}^{D} \\rightarrow \\mathbb{R}\n","\\\\\n","Q(a) = \\sigma(w{^T}a + b)\n","$$\n","\n","with $w{^T}a$ being the dot product of the row vector $w^{T}$ and the column vector $a$.\n","So a neuron accepts $d$ real numbers  $a_1, a_2, ... , a_{D}$ as input and uses $Q$ to process another real number $Q(a)$, $a$ denoting the column vector \n","$(a_1, a_2, ... , a_{D})^T$.\n","\n","We call $a$ the **incoming activation** and $Q(a)$ the **outgoing activation** of the neuron $Q$.\n","\n","\n","## Notation\n","We will often use the following abbreviation:\n","$$\n","z = w^Ta+b\n","$$\n","then\n","$$\n","Q(a) =  \\sigma(z)\n","$$\n","\n","\n","## Activation functions\n","Widely used activation functions are *reLU*, *sigmoid* and *linear*."]},{"cell_type":"markdown","metadata":{"id":"3N5s3F3FFt86","colab_type":"text"},"source":["# A Single Neuron with Phython"]},{"cell_type":"code","metadata":{"id":"VOGGCgoI_K0t","colab_type":"code","colab":{}},"source":["import numpy as np \n","\n","def sigma(z, act_func):\n","    if act_func == 'relu':\n","       return np.maximum(z, np.zeros(z.shape))\n","    \n","    elif act_func == 'sigmoid':\n","      return 1.0/(1.0 + np.exp( -z ))\n","\n","    elif act_func == 'linear':\n","        return z\n","    else:\n","        raise Exception('Activation function is not defined.')\n","\n","class Neuron:\n","  def __init__(self, input_dim, activation):\n","    self.activation_function = activation\n","    self.b = np.zeros( 1 )\n","    self.w = np.zeros( input_dim )\n","  \n","  def set_weight(self, w ):\n","    self.w = w\n","    \n","  def set_bias(self, b ):\n","    self.b = b\n","    \n","  def Q(self, a ):\n","    z =  np.add( np.dot(self.w, a), self.b)\n","    return sigma(z, self.activation_function)\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dnMhe3y0qu5p","colab_type":"text"},"source":["#Test"]},{"cell_type":"code","metadata":{"id":"FtgV9V7iqwNB","colab_type":"code","outputId":"db1e55a7-9cf5-464e-d273-cd47426ad8b3","executionInfo":{"status":"ok","timestamp":1568101567931,"user_tz":-120,"elapsed":607,"user":{"displayName":"Dieter Greipl","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQkt4LlXZTbr43bodLOYJA_AMigYzivO_n1PBIcw=s64","userId":"09839720196215486633"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["# Create the Neuron\n","my_neuron = Neuron(2, 'relu')\n","my_neuron.set_weight(np.array([[3,-3]]) )\n","my_neuron.set_bias( np.array([1]) )\n","\n","# Evaluate\n","a_in  = np.array([[1], [1]])\n","a_out = my_neuron.Q( a_in )\n","print (f\"Outgoing Activation: {a_out}\")\n","print (f\"Shape of aIn       : {a_in.shape}\")\n","print (f\"Shape of w         : {my_neuron.w.shape}\")\n","print (f\"Shape of b         : {my_neuron.b.shape}\")\n","print (f\"Shape of aOut      : {a_out.shape}\")\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Outgoing Activation: [[1.]]\n","Shape of aIn       : (2, 1)\n","Shape of w         : (1, 2)\n","Shape of b         : (1,)\n","Shape of aOut      : (1, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"to_XeFN9NRur","colab_type":"text"},"source":["# Exercise\n","1. Explain the result of the activation!\n","2. Can you explain the math behind this behaviour?\n"]},{"cell_type":"code","metadata":{"id":"IdhCI157NV2T","colab_type":"code","outputId":"0cdd54f3-8657-4306-e543-ad866c4e2b82","executionInfo":{"status":"ok","timestamp":1568101583821,"user_tz":-120,"elapsed":512,"user":{"displayName":"Dieter Greipl","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQkt4LlXZTbr43bodLOYJA_AMigYzivO_n1PBIcw=s64","userId":"09839720196215486633"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["# This neuron works also for several inputs\n","a_in  = np.array([[1,2,3], [1,2,3]])\n","a_out = my_neuron.Q( a_in )\n","print (f\"Outgoing Activation: {a_out}\")\n","print (f\"Shape of aIn       : {a_in.shape}\")\n","print (f\"Shape of w         : {my_neuron.w.shape}\")\n","print (f\"Shape of b         : {my_neuron.b.shape}\")\n","print (f\"Shape of aOut      : {a_out.shape}\")\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Outgoing Activation: [[1. 1. 1.]]\n","Shape of aIn       : (2, 3)\n","Shape of w         : (1, 2)\n","Shape of b         : (1,)\n","Shape of aOut      : (1, 3)\n"],"name":"stdout"}]}]}