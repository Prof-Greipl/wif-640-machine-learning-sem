{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IML_309_Feature Scaling.ipynb","provenance":[{"file_id":"1KbqMz92YgwPjWMafBVhJCXj9r64TsYMZ","timestamp":1567245502602},{"file_id":"1NIIvnmjnRo0DWk3LEQ0CTSXjPOdW_onv","timestamp":1567242361448},{"file_id":"1hqH2_nPaRpEsg1z65rglN-vd4OPo10Id","timestamp":1567239664353},{"file_id":"1610xqRo2kOx8mfvzK3fWft-wNrwBBGPL","timestamp":1566992017998},{"file_id":"1qO3v9wS3vNQRhzyWfw2MJGAuX3TtVw0J","timestamp":1566987247685},{"file_id":"1S9bdyiAEoSoFnub1i90tniJjGu86Y4wu","timestamp":1566986399582}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3JasRRcvdrj9","colab_type":"text"},"source":["# Prep `standardize`-Function"]},{"cell_type":"code","metadata":{"id":"53AWSfT08K_1","colab_type":"code","outputId":"66ddacaf-9a5c-4159-b27b-ce47fb877f63","executionInfo":{"status":"ok","timestamp":1570118280806,"user_tz":-120,"elapsed":548,"user":{"displayName":"Dieter Greipl","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQkt4LlXZTbr43bodLOYJA_AMigYzivO_n1PBIcw=s64","userId":"09839720196215486633"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["import numpy as np\n","\n","def standardize(matrix):\n","    result = np.empty( matrix.shape )    \n","    # run through the lines    \n","    cols = matrix.shape[1]\n","    for i in range( cols ):\n","        col = matrix[:,i]\n","\n","        mean = np.mean(col)\n","        std = np.std(col)\n","\n","        # Handle std = 0 case\n","        if std < 1E-6:\n","          std = 1\n","            \n","        result[:,i] = np.array( (col - mean) / std  )\n","\n","    return result\n","\n","\n","# Test\n","#X  = np.array([[1], [-1]])\n","X  = np.array([[2], [-2]])\n","#X  = np.array( [[0.,1.], [0.,1.]] ) \n","#X  = np.array( [[0.,1., 2.0], [0.,1., 2.0]] )\n","\n","M = standardize( X )\n","print(f\"In \\n {X}\")\n","print(f\"Out\\n {M}\")\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["In \n"," [[ 2]\n"," [-2]]\n","Out\n"," [[ 1.]\n"," [-1.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nRXZ2JSFmXlI","colab_type":"text"},"source":["# LANET: Add Standardizer\n","We just *add* the standardizer to our LANET code. No changes on other code."]},{"cell_type":"code","metadata":{"id":"B_27n1bKPiJf","colab_type":"code","colab":{}},"source":["import numpy as np \n","import pandas as pd\n","from sklearn import metrics\n","\n","def standardize(matrix):\n","    result = np.empty( matrix.shape )    \n","    # run through the lines    \n","    cols = matrix.shape[1]\n","    for i in range( cols ):\n","        col = matrix[:,i]\n","\n","        mean = np.mean(col)\n","        std = np.std(col)\n","\n","        # Handle std = 0 case\n","        if std < 1E-6:\n","          std = 1\n","            \n","        result[:,i] = np.array( (col - mean) / std  )\n","\n","    return result\n","\n","def loss(y_true, y_predicted, loss_function='mse'):\n","    if loss_function == 'mse':       \n","        return metrics.mean_squared_error( y_true, y_predicted)\n","    else:\n","        raise Exception('Loss metric is not defined.')\n","\n","def get_dz_from_loss(y, y_predicted, metric):\n","    if metric == 'mse':\n","        return y_predicted - y\n","    else:\n","        raise Exception('Loss metric is not defined.')\n","\n","def sigma(z, act_func):\n","    global _activation\n","    if act_func == 'relu':\n","       return np.maximum(z, np.zeros(z.shape))\n","    \n","    elif act_func == 'sigmoid':\n","      return 1.0/(1.0 + np.exp( -z ))\n","\n","    elif act_func == 'linear':\n","        return z\n","    else:\n","        raise Exception('Activation function is not defined.')\n","\n","def sigma_prime(z, act_func):\n","    if act_func == 'relu':\n","        return np.maximum(np.sign(z), np.zeros(z.shape)) # 1 if backward input >0, 0 otherwise; then diaganolize\n","\n","    elif act_func == 'sigmoid':\n","        h = sigma(z, 'sigmoid')\n","        return h *(1-h)\n","\n","    elif act_func == 'linear':\n","        return np.ones(z.shape)\n","\n","    else:\n","        raise Exception('Activation function is not defined.')\n","\n","class Layer:\n","    def __init__(self,input_dim, output_dim, activation_function='linear'):    \n","        self.activation = activation_function\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim \n","        if input_dim > 0:\n","            self.b = np.random.randn( output_dim, 1 )       \n","            self.W = np.random.randn( output_dim, input_dim )\n","            self.dW = np.random.randn( output_dim, input_dim )\n","            self.db = np.random.randn( output_dim, 1 )\n","        self.a = np.zeros( (output_dim,1) )\n","\n","    \n","    def set_weight(self, W ):\n","        self.W = W\n","      \n","    def set_bias(self, b ):\n","        self.b = b\n","  \n","    def compute_activation(self, a ): \n","        self.z =  np.add( np.dot(self.W, a), self.b)\n","        self.a =  sigma(self.z, self.activation)\n","    \n","    \n","    def print( self ):      \n","        print(f\"\\n====== Layer Info =======\")\n","        print(f\"a    = {self.a}\")\n","        if self.input_dim > 0: \n","          print(f\"W   =  {self.W}\")          \n","          print(f\"b   =  {self.b}\")  \n","    \n","\n","class Model:\n","    def __init__(self, input_dim):  \n","        self.neural_net = []\n","        self.neural_net.append(Layer(0 , input_dim, 'irrelevant'))    \n","        self.history = []  \n"," \n","          \n","    def fit(self, training_data, epochs, learning_rate=0.001, early_stop = -1, verbose=1 ):\n","          self.learning_rate = learning_rate\n","          self.history = []  \n","\n","          X_train, y_train = training_data\n","          num_train_datum = X_train.shape[1]\n","\n","          print(f\"\\n\\nStart training for following parameters :\")\n","          print(f\" N              =  {num_train_datum}\")\n","          print(f\" Shape of X     =  {X_train.shape}\")\n","          print(f\" Shape of y     =  {y_train.shape}\")\n","          print(f\" epochs         = {epochs}\")\n","          print(f\" learning_rate  =  {learning_rate}\")\n","    \n","          \n","          # Training Loop\n","          for epoch in range(1,epochs+1):        \n","              y_train_predicted = model.forward_propagation( X_train )\n","              self.backward_propagation( y_train, y_train_predicted, num_train_datum, verbose = verbose - 1 )\n","              self.update( learning_rate )\n","                            \n","              ##  - Backpropagation for whole training set is finished\n","              \n","              # After backpropagation\n","              # ... calculate the training loss\n","              y_train_predicted = model.forward_propagation( X_train )\n","              training_loss   = loss(y_train, y_train_predicted)\n","                            \n","              # ... add result to the histoty\n","              self.history.append( [epoch, training_loss])\n","\n","              # ...and finally check, if early_stop applies\n","              if (epoch > 10)  and (early_stop > 0):            \n","                past_loss   = self.history[epoch-6][1] \n","                if (abs(training_loss - past_loss)) < early_stop:\n","                  print(f\"Early stop in after epoch {epoch} with training-loss  {training_loss}\")\n","                  print(f\"   Prev Loss ({epoch-5}) : {past_loss} [Delta: { abs(training_loss-past_loss) }]\")\n","                  break  \n","                  # If requested, print result of this round\n","                  if (verbose > 0):\n","                    print(f\"Epoch {epoch}: Train.-Loss   = { training_loss  }\")\n","\n","          ##### end of training loop \n","          return training_loss\n","\n","\n","    def add_layer(self, nr_neurons, activation='relu'):    \n","        layer_index = len(self.neural_net)\n","        input_dim = self.neural_net[layer_index - 1].output_dim\n","        new_layer = Layer( input_dim, nr_neurons, activation)\n","        self.neural_net.append( new_layer )\n","\n","\n","    def forward_propagation(self, input_vec ):\n","        self.neural_net[0].a = input_vec\n","        for layer_index in range(1,len(self.neural_net)):    \n","            _A_Prev = self.neural_net[layer_index-1].a                       \n","            self.neural_net[layer_index].compute_activation( _A_Prev )\n","        return  self.neural_net[layer_index].a\n","  \n","    def backward_propagation(self, y, y_predicted, num_train_datum, metric='mse', verbose=0):   \n","            nr_layers = len(self.neural_net)\n","            for layer_index in range(nr_layers-1,0,-1):\n","                if layer_index+1 == nr_layers: # if output layer\n","\n","                    dz = np.multiply(get_dz_from_loss(y, y_predicted, metric), \n","                                    sigma_prime(\n","                                        self.neural_net[layer_index].a, \n","                                        self.neural_net[layer_index].activation)\n","                    )        \n","                else: \n","                    dz = np.multiply(\n","                          np.dot(\n","                              self.neural_net[layer_index+1].W.T, \n","                              dz), \n","                          sigma_prime(\n","                                self.neural_net[layer_index].a, \n","                                self.neural_net[layer_index].activation)\n","                          )         \n","                dW = np.dot(dz, self.neural_net[layer_index-1].a.T) / num_train_datum\n","                db = np.sum(dz, axis=1, keepdims=True) / num_train_datum\n","\n","                # Update gradients\n","                self.neural_net[layer_index].dW = dW \n","                self.neural_net[layer_index].db = db \n","\n","                if (verbose > 0):\n","                  print(f\"\\n\\n====== Backward Propagation Layer {layer_index} =======\")\n","                  print(f\"dZ      =  {dz}\")          \n","                  print(f\"dW      =  {dW}\")\n","                  print(f\"db      =  {db}\")\n","                  print(f\"A           = {self.neural_net[layer_index].a}\") \n","                  print(f\"A prev lay  = {self.neural_net[layer_index-1].a}\") \n","                  \n","\n","    def update( self, learning_rate ):\n","        nr_layers = len(self.neural_net)\n","        for layer_index in range(1,nr_layers):        \n","            self.neural_net[layer_index].set_weight( self.neural_net[layer_index].W - learning_rate * self.neural_net[layer_index].dW )\n","            self.neural_net[layer_index].set_bias(  self.neural_net[layer_index].b  - learning_rate * self.neural_net[layer_index].db  )\n","    \n","\n","    def get_history(self):\n","            return pd.DataFrame(\n","                self.history, \n","                columns=['epoch', 'training_loss']\n","            )   \n","\n","    def summary(self):\n","        print(\"MODEL SUMMARY\")\n","        for layer_index in range(len(self.neural_net)):        \n","          self.neural_net[layer_index].print()\n","          \n","        print(\"FINISHED MODEL SUMMARY\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v1X3arZ6VFHM","colab_type":"text"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"ijR4dBiIVKuv","colab_type":"code","outputId":"917af54e-e3ce-4090-8d2d-a77bec18c868","executionInfo":{"status":"ok","timestamp":1570118330786,"user_tz":-120,"elapsed":1125,"user":{"displayName":"Dieter Greipl","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQkt4LlXZTbr43bodLOYJA_AMigYzivO_n1PBIcw=s64","userId":"09839720196215486633"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import matplotlib.pyplot as plt\n","\n","_activation = 0     \n","input_dim = 2\n","output_dim = 1\n","model = Model( input_dim )\n","model.add_layer( 2, 'relu' )\n","model.add_layer( output_dim, 'linear' )\n","\n","X  = np.array( [[0.,-1], [10,0] , [200000,1]] ) \n","print(X.shape)\n","y_true = np.array( [[10., -11., -15.0]] )\n","print (y_true.shape)\n","\n","\n","\n","print(\"Training with scaled data----------------\")\n","\n","max_epoch = 4000\n","early_stop = 1E-3\n","learning_rate = 0.01\n","\n","X_S = standardize( X )\n","model.fit( (X_S.T, y_true), max_epoch, learning_rate = learning_rate , early_stop= early_stop, verbose=0)\n","history_scaled = model.get_history()\n","\n","print(\"Training with unscaled data----------------\")\n","model.fit( (X.T, y_true), max_epoch, learning_rate = learning_rate , early_stop= early_stop, verbose=0)\n","history_unscaled = model.get_history()\n","\n","#Plotting\n","plt.xlabel('Epoch')\n","plt.ylabel('Mean Square Error [MSE]')\n","plt.plot(history_scaled['epoch'], history_scaled['training_loss'], label='Loss (Scaled Data)')\n","plt.plot(history_unscaled['training_loss'], label='Loss (Unscaled Data)')\n","#plt.ylim([0,50])  \n","plt.legend()\n","plt.show()\n","      \n","print(\"Unscaled History \")\n","display ( history_unscaled.head ( 10 ))\n","print(\"Scaled History \")\n","display ( history_scaled.head ( 10 ))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(3, 2)\n","(1, 3)\n","Training with scaled data----------------\n","\n","\n","Start training for following parameters :\n"," N              =  3\n"," Shape of X     =  (2, 3)\n"," Shape of y     =  (1, 3)\n"," epochs         = 4000\n"," learning_rate  =  0.01\n","Early stop in after epoch 912 with training-loss  0.12356331158255528\n","   Prev Loss (907) : 0.12436669404410582 [Delta: 0.0008033824615505392]\n","Training with unscaled data----------------\n","\n","\n","Start training for following parameters :\n"," N              =  3\n"," Shape of X     =  (2, 3)\n"," Shape of y     =  (1, 3)\n"," epochs         = 4000\n"," learning_rate  =  0.01\n","Early stop in after epoch 500 with training-loss  120.23159239894146\n","   Prev Loss (495) : 120.23258308294488 [Delta: 0.0009906840034261677]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP8k0YOvZjmTSAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Unscaled History \n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>epoch</th>\n","      <th>training_loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>332.949691</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>328.716415</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>324.567380</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>320.500912</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>316.515366</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>312.609132</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>308.780633</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>305.028320</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>301.350679</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>297.746223</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   epoch  training_loss\n","0      1     332.949691\n","1      2     328.716415\n","2      3     324.567380\n","3      4     320.500912\n","4      5     316.515366\n","5      6     312.609132\n","6      7     308.780633\n","7      8     305.028320\n","8      9     301.350679\n","9     10     297.746223"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Scaled History \n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>epoch</th>\n","      <th>training_loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>218.224101</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>192.932090</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>175.638384</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>162.555587</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>151.793881</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>142.314560</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>133.521998</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>125.084442</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>116.847005</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>108.782625</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   epoch  training_loss\n","0      1     218.224101\n","1      2     192.932090\n","2      3     175.638384\n","3      4     162.555587\n","4      5     151.793881\n","5      6     142.314560\n","6      7     133.521998\n","7      8     125.084442\n","8      9     116.847005\n","9     10     108.782625"]},"metadata":{"tags":[]}}]}]}